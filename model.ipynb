{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restarting March Madness prediction with XGBoost only\n",
      "\n",
      "---------- Loading Pre-processed Stats ----------\n",
      "Loaded men's team stats with 13388 rows\n",
      "Loaded women's team stats with 9488 rows\n",
      "Loading minimal data files needed for prediction...\n",
      "Loading m_reg_results...\n",
      "Loading w_reg_results...\n",
      "Loading m_tourney_results...\n",
      "Loading w_tourney_results...\n",
      "\n",
      "---------- Training Men's Model ----------\n",
      "Checking for pre-computed men's matchups...\n",
      "Creating matchup features for training...\n",
      "Creating matchups for season 1985\n",
      "Creating 39621 matchups for 282 teams\n",
      "Creating matchups for season 1986\n",
      "Creating 39903 matchups for 283 teams\n",
      "Creating matchups for season 1987\n",
      "Creating 41905 matchups for 290 teams\n",
      "Creating matchups for season 1988\n",
      "Creating 41905 matchups for 290 teams\n",
      "Creating matchups for season 1989\n",
      "Creating 42778 matchups for 293 teams\n",
      "Creating matchups for season 1990\n",
      "Creating 42486 matchups for 292 teams\n",
      "Creating matchups for season 1991\n",
      "Creating 43365 matchups for 295 teams\n",
      "Creating matchups for season 1992\n",
      "Creating 44253 matchups for 298 teams\n",
      "Creating matchups for season 1993\n",
      "Creating 44253 matchups for 298 teams\n",
      "Creating matchups for season 1994\n",
      "Creating 45150 matchups for 301 teams\n",
      "Creating matchups for season 1995\n",
      "Creating 45451 matchups for 302 teams\n",
      "Creating matchups for season 1996\n",
      "Creating 46360 matchups for 305 teams\n",
      "Creating matchups for season 1997\n",
      "Creating 46360 matchups for 305 teams\n",
      "Creating matchups for season 1998\n",
      "Creating 46665 matchups for 306 teams\n",
      "Creating matchups for season 1999\n",
      "Creating 47895 matchups for 310 teams\n",
      "Creating matchups for season 2000\n",
      "Creating 50403 matchups for 318 teams\n",
      "Creating matchups for season 2001\n",
      "Creating 50403 matchups for 318 teams\n",
      "Creating matchups for season 2002\n",
      "Creating 51360 matchups for 321 teams\n",
      "Creating matchups for season 2003\n",
      "Creating 53301 matchups for 327 teams\n",
      "Creating matchups for season 2004\n",
      "Creating 52975 matchups for 326 teams\n",
      "Creating matchups for season 2005\n",
      "Creating 54285 matchups for 330 teams\n",
      "Creating matchups for season 2006\n",
      "Creating 55611 matchups for 334 teams\n",
      "Creating matchups for season 2007\n",
      "Creating 56280 matchups for 336 teams\n",
      "Creating matchups for season 2008\n",
      "Creating 58311 matchups for 342 teams\n",
      "Creating matchups for season 2009\n",
      "Creating 60031 matchups for 347 teams\n",
      "Creating matchups for season 2010\n",
      "Creating 60031 matchups for 347 teams\n",
      "Creating matchups for season 2011\n",
      "Creating 59340 matchups for 345 teams\n",
      "Creating matchups for season 2012\n",
      "Creating 59340 matchups for 345 teams\n",
      "Creating matchups for season 2013\n",
      "Creating 60031 matchups for 347 teams\n",
      "Creating matchups for season 2014\n",
      "Creating 61425 matchups for 351 teams\n",
      "Creating matchups for season 2015\n",
      "Creating 61425 matchups for 351 teams\n",
      "Creating matchups for season 2016\n",
      "Creating 61425 matchups for 351 teams\n",
      "Creating matchups for season 2017\n",
      "Creating 61425 matchups for 351 teams\n",
      "Creating matchups for season 2018\n",
      "Creating 61425 matchups for 351 teams\n",
      "Creating matchups for season 2019\n",
      "Creating 62128 matchups for 353 teams\n",
      "Creating matchups for season 2020\n",
      "Creating 62128 matchups for 353 teams\n",
      "Creating matchups for season 2021\n",
      "Creating 60031 matchups for 347 teams\n",
      "Creating matchups for season 2022\n",
      "Creating 63903 matchups for 358 teams\n",
      "Creating matchups for season 2023\n",
      "Creating 65703 matchups for 363 teams\n",
      "Creating matchups for season 2024\n",
      "Creating 65341 matchups for 362 teams\n",
      "Creating matchups for season 2025\n",
      "Creating 66066 matchups for 364 teams\n",
      "Saved men's matchups to ./m_matchups.csv\n",
      "Preparing men's training data...\n",
      "Merging game results with features...\n",
      "Training data shape: (195448, 93)\n",
      "Starting train_cv_model...\n",
      "Training fold 1/5\n",
      "[0]\tvalidation_0-logloss:0.67634\n",
      "[100]\tvalidation_0-logloss:0.48382\n",
      "[156]\tvalidation_0-logloss:0.48279\n",
      "Fold 1 Brier Score: 0.161201\n",
      "Training fold 2/5\n",
      "[0]\tvalidation_0-logloss:0.67624\n",
      "[100]\tvalidation_0-logloss:0.48009\n",
      "[168]\tvalidation_0-logloss:0.47927\n",
      "Fold 2 Brier Score: 0.160105\n",
      "Training fold 3/5\n",
      "[0]\tvalidation_0-logloss:0.67625\n",
      "[100]\tvalidation_0-logloss:0.47963\n",
      "[197]\tvalidation_0-logloss:0.47857\n",
      "Fold 3 Brier Score: 0.159774\n",
      "Training fold 4/5\n",
      "[0]\tvalidation_0-logloss:0.67631\n",
      "[100]\tvalidation_0-logloss:0.47934\n",
      "[199]\tvalidation_0-logloss:0.47808\n",
      "Fold 4 Brier Score: 0.160124\n",
      "Training fold 5/5\n",
      "[0]\tvalidation_0-logloss:0.67640\n",
      "[100]\tvalidation_0-logloss:0.48270\n",
      "[196]\tvalidation_0-logloss:0.48186\n",
      "Fold 5 Brier Score: 0.161325\n",
      "Mean Brier Score: 0.160506\n",
      "Completed train_cv_model in 5.09 seconds\n",
      "\n",
      "Attempting LightGBM training with modified code...\n",
      "Starting train_cv_model...\n",
      "Training fold 1/5\n",
      "Fitting LightGBM without early stopping\n",
      "Error in fold 1: LGBMClassifier.fit() got an unexpected keyword argument 'verbose'\n",
      "Continuing with next fold...\n",
      "Training fold 2/5\n",
      "Fitting LightGBM without early stopping\n",
      "Error in fold 2: LGBMClassifier.fit() got an unexpected keyword argument 'verbose'\n",
      "Continuing with next fold...\n",
      "Training fold 3/5\n",
      "Fitting LightGBM without early stopping\n",
      "Error in fold 3: LGBMClassifier.fit() got an unexpected keyword argument 'verbose'\n",
      "Continuing with next fold...\n",
      "Training fold 4/5\n",
      "Fitting LightGBM without early stopping\n",
      "Error in fold 4: LGBMClassifier.fit() got an unexpected keyword argument 'verbose'\n",
      "Continuing with next fold...\n",
      "Training fold 5/5\n",
      "Fitting LightGBM without early stopping\n",
      "Error in fold 5: LGBMClassifier.fit() got an unexpected keyword argument 'verbose'\n",
      "Continuing with next fold...\n",
      "LightGBM training failed: All model training attempts failed. Check your data and parameters.\n",
      "Proceeding with XGBoost model only\n",
      "\n",
      "---------- Generating Men's Predictions ----------\n",
      "Creating matchup features for 2025...\n",
      "Creating 66066 matchups for 364 teams\n",
      "Processing batch 1/7\n",
      "Processing batch 2/7\n",
      "Processing batch 3/7\n",
      "Processing batch 4/7\n",
      "Processing batch 5/7\n",
      "Processing batch 6/7\n",
      "Processing batch 7/7\n",
      "\n",
      "---------- Training Women's Model & Generating Predictions ----------\n",
      "Creating matchup features for 2025...\n",
      "Creating 65341 matchups for 362 teams\n",
      "\n",
      "Predictions saved to ./submission.csv\n",
      "Total execution time: 20.50 minutes\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set GPU acceleration for XGBoost and LightGBM\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "def log_time(func):\n",
    "    \"\"\"Decorator to log function execution time\"\"\"\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        print(f\"Starting {func.__name__}...\")\n",
    "        result = func(*args, **kwargs)\n",
    "        elapsed = time.time() - start\n",
    "        print(f\"Completed {func.__name__} in {elapsed:.2f} seconds\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "@log_time\n",
    "def train_cv_model(X, y, model_type='xgb', n_folds=5):\n",
    "    \"\"\"Train a model with cross-validation for better generalization\"\"\"\n",
    "    # Ensure numeric data types\n",
    "    X = X.astype('float32')  # Use float32 to reduce memory usage\n",
    "    \n",
    "    # Initialize cross-validation\n",
    "    kfold = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Model parameters\n",
    "    if model_type == 'xgb':\n",
    "        # For newer XGBoost versions (>= 1.6.0)\n",
    "        params = {\n",
    "            'objective': 'binary:logistic',\n",
    "            'eval_metric': 'logloss',\n",
    "            'tree_method': 'gpu_hist',  # GPU acceleration\n",
    "            'predictor': 'gpu_predictor',  # GPU acceleration\n",
    "            'learning_rate': 0.05,\n",
    "            'max_depth': 5,\n",
    "            'n_estimators': 200,\n",
    "            'subsample': 0.8,\n",
    "            'colsample_bytree': 0.8,\n",
    "            'random_state': 42,\n",
    "            # Early stopping is now here for newer XGBoost\n",
    "            'early_stopping_rounds': 20\n",
    "        }\n",
    "    elif model_type == 'lgb':\n",
    "        params = {\n",
    "            'objective': 'binary',\n",
    "            'metric': 'binary_logloss',\n",
    "            'device': 'gpu',  # GPU acceleration\n",
    "            'learning_rate': 0.05,\n",
    "            'max_depth': 5,\n",
    "            'n_estimators': 200,\n",
    "            'subsample': 0.8,\n",
    "            'colsample_bytree': 0.8,\n",
    "            'random_state': 42\n",
    "        }\n",
    "    \n",
    "    # Train models with cross-validation\n",
    "    models = []\n",
    "    fold_scores = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(X, y)):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        print(f\"Training fold {fold+1}/{n_folds}\")\n",
    "        \n",
    "        try:\n",
    "            if model_type == 'xgb':\n",
    "                # Try with newer XGBoost API\n",
    "                model = xgb.XGBClassifier(**params)\n",
    "                # Handle both newer and older XGBoost versions\n",
    "                try:\n",
    "                    model.fit(\n",
    "                        X_train, y_train,\n",
    "                        eval_set=[(X_val, y_val)],\n",
    "                        verbose=100\n",
    "                    )\n",
    "                except TypeError:\n",
    "                    # For older XGBoost versions that expect early_stopping_rounds in fit()\n",
    "                    old_params = params.copy()\n",
    "                    if 'early_stopping_rounds' in old_params:\n",
    "                        early_stopping = old_params.pop('early_stopping_rounds')\n",
    "                        model = xgb.XGBClassifier(**old_params)\n",
    "                        model.fit(\n",
    "                            X_train, y_train,\n",
    "                            eval_set=[(X_val, y_val)],\n",
    "                            early_stopping_rounds=early_stopping,\n",
    "                            verbose=100\n",
    "                        )\n",
    "                    \n",
    "            elif model_type == 'lgb':\n",
    "                model = lgb.LGBMClassifier(**params)\n",
    "                \n",
    "                # Try different approaches for LightGBM based on version\n",
    "                try:\n",
    "                    # Try with callbacks approach (newer LightGBM)\n",
    "                    callbacks = [lgb.early_stopping(20)]\n",
    "                    model.fit(\n",
    "                        X_train, y_train,\n",
    "                        eval_set=[(X_val, y_val)],\n",
    "                        callbacks=callbacks,\n",
    "                        verbose=100\n",
    "                    )\n",
    "                except (TypeError, AttributeError):\n",
    "                    try:\n",
    "                        # Try standard approach with early_stopping_rounds\n",
    "                        model.fit(\n",
    "                            X_train, y_train,\n",
    "                            eval_set=[(X_val, y_val)],\n",
    "                            early_stopping_rounds=20,\n",
    "                            verbose=100\n",
    "                        )\n",
    "                    except TypeError:\n",
    "                        # Last resort: just fit without early stopping\n",
    "                        print(\"Fitting LightGBM without early stopping\")\n",
    "                        model.fit(\n",
    "                            X_train, y_train,\n",
    "                            eval_set=[(X_val, y_val)],\n",
    "                            verbose=100\n",
    "                        )\n",
    "                \n",
    "            # Calibrate probabilities\n",
    "            calibrated_model = CalibratedClassifierCV(model, cv='prefit')\n",
    "            calibrated_model.fit(X_val, y_val)\n",
    "            \n",
    "            # Evaluate\n",
    "            y_pred = calibrated_model.predict_proba(X_val)[:, 1]\n",
    "            brier = brier_score_loss(y_val, y_pred)\n",
    "            print(f\"Fold {fold+1} Brier Score: {brier:.6f}\")\n",
    "            \n",
    "            models.append(calibrated_model)\n",
    "            fold_scores.append(brier)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in fold {fold+1}: {e}\")\n",
    "            print(\"Continuing with next fold...\")\n",
    "            continue\n",
    "    \n",
    "    if not models:\n",
    "        raise Exception(\"All model training attempts failed. Check your data and parameters.\")\n",
    "    \n",
    "    print(f\"Mean Brier Score: {np.mean(fold_scores):.6f}\")\n",
    "    \n",
    "    # Return both the list of models and their scores\n",
    "    return models, fold_scores\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to restart training with only XGBoost\"\"\"\n",
    "    start_time = time.time()\n",
    "    print(\"Restarting March Madness prediction with XGBoost only\")\n",
    "    \n",
    "    # Configure paths - adjust this to your data location\n",
    "    base_dir = \"./data/\"\n",
    "    output_dir = \"./\"\n",
    "    \n",
    "    try:\n",
    "        # Load the pre-processed team stats files\n",
    "        print(\"\\n---------- Loading Pre-processed Stats ----------\")\n",
    "        m_team_stats = pd.read_csv(f\"{output_dir}m_team_stats.csv\")\n",
    "        print(f\"Loaded men's team stats with {len(m_team_stats)} rows\")\n",
    "        \n",
    "        w_team_stats = pd.read_csv(f\"{output_dir}w_team_stats.csv\")\n",
    "        print(f\"Loaded women's team stats with {len(w_team_stats)} rows\")\n",
    "        \n",
    "        # Load minimal data needed for training\n",
    "        print(\"Loading minimal data files needed for prediction...\")\n",
    "        data = {}\n",
    "        files = {\n",
    "            \"m_reg_results\": f\"{base_dir}MRegularSeasonCompactResults.csv\",\n",
    "            \"w_reg_results\": f\"{base_dir}WRegularSeasonCompactResults.csv\",\n",
    "            \"m_tourney_results\": f\"{base_dir}MNCAATourneyCompactResults.csv\",\n",
    "            \"w_tourney_results\": f\"{base_dir}WNCAATourneyCompactResults.csv\"\n",
    "        }\n",
    "        \n",
    "        # Define datatypes to reduce memory usage\n",
    "        dtypes = {\n",
    "            'Season': 'int16',\n",
    "            'DayNum': 'int16',\n",
    "            'WTeamID': 'int16',\n",
    "            'LTeamID': 'int16',\n",
    "            'WScore': 'int16',\n",
    "            'LScore': 'int16',\n",
    "            'NumOT': 'int8'\n",
    "        }\n",
    "        \n",
    "        for name, file_path in files.items():\n",
    "            try:\n",
    "                print(f\"Loading {name}...\")\n",
    "                data[name] = pd.read_csv(file_path, dtype=dtypes)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {name}: {e}\")\n",
    "                data[name] = None\n",
    "        \n",
    "        # Create training data for men\n",
    "        print(\"\\n---------- Training Men's Model ----------\")\n",
    "        # Combine regular season and tournament results\n",
    "        m_all_results = pd.concat([data['m_reg_results'], data['m_tourney_results']])\n",
    "        \n",
    "        # Create matchup features only for seasons where we have results (to save time)\n",
    "        train_seasons = m_all_results['Season'].unique()\n",
    "        m_train_stats = m_team_stats[m_team_stats['Season'].isin(train_seasons)]\n",
    "        \n",
    "        # Try to load pre-computed matchups if available\n",
    "        try:\n",
    "            print(\"Checking for pre-computed men's matchups...\")\n",
    "            m_matchups = pd.read_csv(f\"{output_dir}m_matchups.csv\")\n",
    "            print(f\"Loaded pre-computed men's matchups with {len(m_matchups)} rows\")\n",
    "        except FileNotFoundError:\n",
    "            print(\"Creating matchup features for training...\")\n",
    "            \n",
    "            # Create features for each season\n",
    "            seasons = sorted(m_train_stats['Season'].unique())\n",
    "            all_matchups = []\n",
    "            \n",
    "            for season in seasons:\n",
    "                print(f\"Creating matchups for season {season}\")\n",
    "                season_stats = m_train_stats[m_train_stats['Season'] == season]\n",
    "                \n",
    "                # Get all teams in the season\n",
    "                teams = season_stats['TeamID'].unique()\n",
    "                total_matchups = len(teams) * (len(teams) - 1) // 2\n",
    "                print(f\"Creating {total_matchups} matchups for {len(teams)} teams\")\n",
    "                \n",
    "                matchups = []\n",
    "                for i, team1_id in enumerate(teams):\n",
    "                    for team2_id in teams[i+1:]:\n",
    "                        team1_stats = season_stats[season_stats['TeamID'] == team1_id].iloc[0]\n",
    "                        team2_stats = season_stats[season_stats['TeamID'] == team2_id].iloc[0]\n",
    "                        \n",
    "                        # Calculate differential features\n",
    "                        matchup_features = {\n",
    "                            'Season': season,\n",
    "                            'Team1ID': team1_id,\n",
    "                            'Team2ID': team2_id\n",
    "                        }\n",
    "                        \n",
    "                        # Basic stat differences (exclude non-numeric and ID columns)\n",
    "                        exclude_cols = ['Season', 'TeamID', 'ConfAbbrev']\n",
    "                        numeric_cols = [col for col in team1_stats.index \n",
    "                                      if col not in exclude_cols and isinstance(team1_stats[col], (int, float))]\n",
    "                        \n",
    "                        for col in numeric_cols:\n",
    "                            matchup_features[f'{col}_1'] = team1_stats[col]\n",
    "                            matchup_features[f'{col}_2'] = team2_stats[col]\n",
    "                            matchup_features[f'{col}_diff'] = team1_stats[col] - team2_stats[col]\n",
    "                        \n",
    "                        matchups.append(matchup_features)\n",
    "                    \n",
    "                    # Free memory regularly\n",
    "                    if i % 100 == 0 and i > 0:\n",
    "                        gc.collect()\n",
    "                \n",
    "                all_matchups.extend(matchups)\n",
    "                \n",
    "                # Clean up to save memory\n",
    "                del matchups, season_stats\n",
    "                gc.collect()\n",
    "            \n",
    "            m_matchups = pd.DataFrame(all_matchups)\n",
    "            \n",
    "            # Save to avoid recomputing\n",
    "            m_matchups.to_csv(f\"{output_dir}m_matchups.csv\", index=False)\n",
    "            print(f\"Saved men's matchups to {output_dir}m_matchups.csv\")\n",
    "        \n",
    "        print(\"Preparing men's training data...\")\n",
    "        \n",
    "        # Get game results\n",
    "        game_results = []\n",
    "        for _, row in m_all_results.iterrows():\n",
    "            season = row['Season']\n",
    "            w_team = row['WTeamID']\n",
    "            l_team = row['LTeamID']\n",
    "            \n",
    "            # Ensure Team1 is always the lower ID\n",
    "            team1 = min(w_team, l_team)\n",
    "            team2 = max(w_team, l_team)\n",
    "            \n",
    "            game_results.append({\n",
    "                'Season': season,\n",
    "                'Team1ID': team1,\n",
    "                'Team2ID': team2,\n",
    "                'Team1Win': 1 if team1 == w_team else 0\n",
    "            })\n",
    "        \n",
    "        game_results_df = pd.DataFrame(game_results)\n",
    "        \n",
    "        # Merge game results with matchup features\n",
    "        print(\"Merging game results with features...\")\n",
    "        m_training_data = pd.merge(\n",
    "            m_matchups,\n",
    "            game_results_df,\n",
    "            on=['Season', 'Team1ID', 'Team2ID'],\n",
    "            how='inner'\n",
    "        )\n",
    "        \n",
    "        # Split features and target\n",
    "        m_X = m_training_data.drop(['Season', 'Team1ID', 'Team2ID', 'Team1Win'], axis=1)\n",
    "        m_y = m_training_data['Team1Win']\n",
    "        \n",
    "        # Handle NaN values\n",
    "        m_X = m_X.fillna(0)\n",
    "        \n",
    "        print(f\"Training data shape: {m_X.shape}\")\n",
    "        \n",
    "        # Train men's XGBoost models\n",
    "        m_xgb_models, m_xgb_scores = train_cv_model(m_X, m_y, model_type='xgb')\n",
    "        \n",
    "        # Try LightGBM training with modified code\n",
    "        try:\n",
    "            print(\"\\nAttempting LightGBM training with modified code...\")\n",
    "            m_lgb_models, m_lgb_scores = train_cv_model(m_X, m_y, model_type='lgb')\n",
    "            \n",
    "            # Create men's ensemble if both models worked\n",
    "            m_ensemble = create_ensemble(m_xgb_models, m_lgb_models, m_xgb_scores, m_lgb_scores)\n",
    "            print(\"Successfully created ensemble model with XGBoost and LightGBM\")\n",
    "        except Exception as e:\n",
    "            print(f\"LightGBM training failed: {e}\")\n",
    "            print(\"Proceeding with XGBoost model only\")\n",
    "            \n",
    "            # If LightGBM fails, use only XGBoost predictions\n",
    "            def m_ensemble(X_pred):\n",
    "                X_pred = X_pred.fillna(0)\n",
    "                X_pred = X_pred.astype('float32')\n",
    "                \n",
    "                # Average predictions from all XGBoost models\n",
    "                xgb_preds = np.zeros(len(X_pred))\n",
    "                for model in m_xgb_models:\n",
    "                    xgb_preds += model.predict_proba(X_pred)[:, 1]\n",
    "                \n",
    "                return xgb_preds / len(m_xgb_models)\n",
    "        \n",
    "        # Generate men's predictions\n",
    "        print(\"\\n---------- Generating Men's Predictions ----------\")\n",
    "        m_season_stats = m_team_stats[m_team_stats['Season'] == 2025]\n",
    "        \n",
    "        # Create matchup features for 2025\n",
    "        print(\"Creating matchup features for 2025...\")\n",
    "        teams = m_season_stats['TeamID'].unique()\n",
    "        total_matchups = len(teams) * (len(teams) - 1) // 2\n",
    "        print(f\"Creating {total_matchups} matchups for {len(teams)} teams\")\n",
    "        \n",
    "        m_2025_matchups = []\n",
    "        for i, team1_id in enumerate(teams):\n",
    "            for team2_id in teams[i+1:]:\n",
    "                team1_stats = m_season_stats[m_season_stats['TeamID'] == team1_id].iloc[0]\n",
    "                team2_stats = m_season_stats[m_season_stats['TeamID'] == team2_id].iloc[0]\n",
    "                \n",
    "                # Calculate differential features\n",
    "                matchup_features = {\n",
    "                    'Season': 2025,\n",
    "                    'Team1ID': team1_id,\n",
    "                    'Team2ID': team2_id\n",
    "                }\n",
    "                \n",
    "                # Basic stat differences (exclude non-numeric and ID columns)\n",
    "                exclude_cols = ['Season', 'TeamID', 'ConfAbbrev']\n",
    "                numeric_cols = [col for col in team1_stats.index \n",
    "                               if col not in exclude_cols and isinstance(team1_stats[col], (int, float))]\n",
    "                \n",
    "                for col in numeric_cols:\n",
    "                    matchup_features[f'{col}_1'] = team1_stats[col]\n",
    "                    matchup_features[f'{col}_2'] = team2_stats[col]\n",
    "                    matchup_features[f'{col}_diff'] = team1_stats[col] - team2_stats[col]\n",
    "                \n",
    "                m_2025_matchups.append(matchup_features)\n",
    "            \n",
    "            # Free memory regularly\n",
    "            if i % 100 == 0 and i > 0:\n",
    "                gc.collect()\n",
    "        \n",
    "        m_2025_matchups_df = pd.DataFrame(m_2025_matchups)\n",
    "        \n",
    "        # Prepare features for prediction\n",
    "        X_pred = m_2025_matchups_df.drop(['Season', 'Team1ID', 'Team2ID'], axis=1)\n",
    "        X_pred = X_pred.fillna(0)\n",
    "        \n",
    "        # Make predictions in batches to manage memory\n",
    "        batch_size = 10000\n",
    "        predictions = []\n",
    "        total_batches = (len(X_pred) + batch_size - 1) // batch_size\n",
    "        \n",
    "        for i in range(0, len(X_pred), batch_size):\n",
    "            batch_end = min(i + batch_size, len(X_pred))\n",
    "            print(f\"Processing batch {i//batch_size + 1}/{total_batches}\")\n",
    "            \n",
    "            batch = X_pred.iloc[i:batch_end]\n",
    "            batch_preds = m_ensemble(batch)\n",
    "            predictions.extend(batch_preds)\n",
    "        \n",
    "        # Create submission format\n",
    "        m_predictions = pd.DataFrame({\n",
    "            'ID': m_2025_matchups_df.apply(\n",
    "                lambda x: f\"{x['Season']}_{x['Team1ID']}_{x['Team2ID']}\", axis=1\n",
    "            ),\n",
    "            'Pred': predictions\n",
    "        })\n",
    "        \n",
    "        # Generate women's predictions using XGBoost only\n",
    "        print(\"\\n---------- Training Women's Model & Generating Predictions ----------\")\n",
    "        # Create matchup features only for 2025 (for submission)\n",
    "        w_season_stats = w_team_stats[w_team_stats['Season'] == 2025]\n",
    "        \n",
    "        # Create matchup features for 2025\n",
    "        print(\"Creating matchup features for 2025...\")\n",
    "        teams = w_season_stats['TeamID'].unique()\n",
    "        total_matchups = len(teams) * (len(teams) - 1) // 2\n",
    "        print(f\"Creating {total_matchups} matchups for {len(teams)} teams\")\n",
    "        \n",
    "        w_2025_matchups = []\n",
    "        for i, team1_id in enumerate(teams):\n",
    "            for team2_id in teams[i+1:]:\n",
    "                team1_stats = w_season_stats[w_season_stats['TeamID'] == team1_id].iloc[0]\n",
    "                team2_stats = w_season_stats[w_season_stats['TeamID'] == team2_id].iloc[0]\n",
    "                \n",
    "                # Calculate differential features\n",
    "                matchup_features = {\n",
    "                    'Season': 2025,\n",
    "                    'Team1ID': team1_id,\n",
    "                    'Team2ID': team2_id\n",
    "                }\n",
    "                \n",
    "                # Basic stat differences (exclude non-numeric and ID columns)\n",
    "                exclude_cols = ['Season', 'TeamID', 'ConfAbbrev']\n",
    "                numeric_cols = [col for col in team1_stats.index \n",
    "                               if col not in exclude_cols and isinstance(team1_stats[col], (int, float))]\n",
    "                \n",
    "                for col in numeric_cols:\n",
    "                    matchup_features[f'{col}_1'] = team1_stats[col]\n",
    "                    matchup_features[f'{col}_2'] = team2_stats[col]\n",
    "                    matchup_features[f'{col}_diff'] = team1_stats[col] - team2_stats[col]\n",
    "                \n",
    "                w_2025_matchups.append(matchup_features)\n",
    "            \n",
    "            # Free memory regularly\n",
    "            if i % 100 == 0 and i > 0:\n",
    "                gc.collect()\n",
    "        \n",
    "        w_2025_matchups_df = pd.DataFrame(w_2025_matchups)\n",
    "        \n",
    "        # Use a constant prediction of 0.5 for women's games (baseline)\n",
    "        # You can improve this later by training a model on women's data\n",
    "        w_predictions = pd.DataFrame({\n",
    "            'ID': w_2025_matchups_df.apply(\n",
    "                lambda x: f\"{x['Season']}_{x['Team1ID']}_{x['Team2ID']}\", axis=1\n",
    "            ),\n",
    "            'Pred': [0.5] * len(w_2025_matchups_df)\n",
    "        })\n",
    "        \n",
    "        # Combine and save predictions\n",
    "        all_predictions = pd.concat([m_predictions, w_predictions])\n",
    "        all_predictions.to_csv(f\"{output_dir}submission.csv\", index=False)\n",
    "        \n",
    "        print(f\"\\nPredictions saved to {output_dir}submission.csv\")\n",
    "        print(f\"Total execution time: {(time.time() - start_time) / 60:.2f} minutes\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        print(\"Please check your data and try again.\")\n",
    "\n",
    "def create_ensemble(xgb_models, lgb_models, xgb_scores, lgb_scores):\n",
    "    \"\"\"Create a weighted ensemble of multiple models\"\"\"\n",
    "    # Convert scores to weights (lower score = better model = higher weight)\n",
    "    def scores_to_weights(scores):\n",
    "        scores = np.array(scores)\n",
    "        # Invert scores (lower is better) and normalize\n",
    "        weights = 1 / (scores + 1e-10)  # Add small epsilon to avoid division by zero\n",
    "        return weights / weights.sum()\n",
    "    \n",
    "    xgb_weights = scores_to_weights(xgb_scores)\n",
    "    lgb_weights = scores_to_weights(lgb_scores)\n",
    "    \n",
    "    # Normalize weights between model types\n",
    "    xgb_mean_score = np.mean(xgb_scores)\n",
    "    lgb_mean_score = np.mean(lgb_scores)\n",
    "    \n",
    "    total_weight = 1 / (xgb_mean_score + 1e-10) + 1 / (lgb_mean_score + 1e-10)\n",
    "    xgb_overall_weight = (1 / (xgb_mean_score + 1e-10)) / total_weight\n",
    "    lgb_overall_weight = (1 / (lgb_mean_score + 1e-10)) / total_weight\n",
    "    \n",
    "    print(f\"Ensemble weights - XGB: {xgb_overall_weight:.2f}, LGB: {lgb_overall_weight:.2f}\")\n",
    "    \n",
    "    # Create ensemble prediction function\n",
    "    def ensemble_predict(X_pred):\n",
    "        # Handle NaN values\n",
    "        X_pred = X_pred.fillna(0)\n",
    "        X_pred = X_pred.astype('float32')\n",
    "        \n",
    "        # Get predictions from each model\n",
    "        xgb_preds = np.zeros(len(X_pred))\n",
    "        for i, model in enumerate(xgb_models):\n",
    "            xgb_preds += xgb_weights[i] * model.predict_proba(X_pred)[:, 1]\n",
    "        \n",
    "        lgb_preds = np.zeros(len(X_pred))\n",
    "        for i, model in enumerate(lgb_models):\n",
    "            lgb_preds += lgb_weights[i] * model.predict_proba(X_pred)[:, 1]\n",
    "        \n",
    "        # Weighted ensemble\n",
    "        return xgb_overall_weight * xgb_preds + lgb_overall_weight * lgb_preds\n",
    "    \n",
    "    return ensemble_predict\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of the submission file:\n",
      "                     ID      Pred\n",
      "0  2025.0_1101.0_1102.0  0.775488\n",
      "1  2025.0_1101.0_1103.0  0.098356\n",
      "2  2025.0_1101.0_1104.0  0.067566\n",
      "3  2025.0_1101.0_1105.0  0.886494\n",
      "4  2025.0_1101.0_1106.0  0.631665\n",
      "\n",
      "Extracting ID parts...\n",
      "Sample IDs: ['2025.0_1101.0_1102.0', '2025.0_1101.0_1103.0', '2025.0_1101.0_1104.0', '2025.0_1101.0_1105.0', '2025.0_1101.0_1106.0']\n",
      "\n",
      "After extraction:\n",
      "                     ID Season  Team1ID  Team2ID\n",
      "0  2025.0_1101.0_1102.0   2025     1101     1102\n",
      "1  2025.0_1101.0_1103.0   2025     1101     1103\n",
      "2  2025.0_1101.0_1104.0   2025     1101     1104\n",
      "3  2025.0_1101.0_1105.0   2025     1101     1105\n",
      "4  2025.0_1101.0_1106.0   2025     1101     1106\n",
      "\n",
      "Top 10 most confident predictions:\n",
      "                         ID      Pred  Team1ID  Team2ID  Confidence\n",
      "16215  2025.0_1154.0_1397.0  0.065607     1154     1397    0.934393\n",
      "6080   2025.0_1120.0_1170.0  0.934357     1120     1170    0.934357\n",
      "6212   2025.0_1120.0_1306.0  0.934350     1120     1306    0.934350\n",
      "16409  2025.0_1155.0_1271.0  0.934337     1155     1271    0.934337\n",
      "28502  2025.0_1196.0_1312.0  0.934337     1196     1312    0.934337\n",
      "6179   2025.0_1120.0_1271.0  0.934333     1120     1271    0.934333\n",
      "28463  2025.0_1196.0_1271.0  0.934320     1196     1271    0.934320\n",
      "6218   2025.0_1120.0_1312.0  0.934319     1120     1312    0.934319\n",
      "6378   2025.0_1120.0_1478.0  0.934316     1120     1478    0.934316\n",
      "6064   2025.0_1120.0_1154.0  0.934314     1120     1154    0.934314\n",
      "\n",
      "Attempting to load team names...\n",
      "Found teams files in ./data/\n",
      "Loaded 758 teams\n",
      "\n",
      "Sample with team names:\n",
      "     Team1Name       Team2Name PredictedWinner  WinProbability\n",
      "0  Abilene Chr       Air Force     Abilene Chr        0.775488\n",
      "1  Abilene Chr           Akron           Akron        0.901644\n",
      "2  Abilene Chr         Alabama         Alabama        0.932434\n",
      "3  Abilene Chr     Alabama A&M     Abilene Chr        0.886494\n",
      "4  Abilene Chr      Alabama St     Abilene Chr        0.631665\n",
      "5  Abilene Chr     SUNY Albany     Abilene Chr        0.507363\n",
      "6  Abilene Chr       Alcorn St     Abilene Chr        0.803318\n",
      "7  Abilene Chr   American Univ   American Univ        0.747609\n",
      "8  Abilene Chr  Appalachian St  Appalachian St        0.707745\n",
      "9  Abilene Chr         Arizona         Arizona        0.930491\n",
      "\n",
      "Most confident predictions:\n",
      "Team1ID beats Team2ID with probability Pred\n",
      "Team 1397 wins: 1154 vs 1397 with 0.9344 probability\n",
      "Team 1120 wins: 1120 vs 1170 with 0.9344 probability\n",
      "Team 1120 wins: 1120 vs 1306 with 0.9343 probability\n",
      "Team 1155 wins: 1155 vs 1271 with 0.9343 probability\n",
      "Team 1196 wins: 1196 vs 1312 with 0.9343 probability\n",
      "Team 1120 wins: 1120 vs 1271 with 0.9343 probability\n",
      "Team 1196 wins: 1196 vs 1271 with 0.9343 probability\n",
      "Team 1120 wins: 1120 vs 1312 with 0.9343 probability\n",
      "Team 1120 wins: 1120 vs 1478 with 0.9343 probability\n",
      "Team 1120 wins: 1120 vs 1154 with 0.9343 probability\n",
      "Team 1397 wins: 1290 vs 1397 with 0.9343 probability\n",
      "Team 1196 wins: 1196 vs 1419 with 0.9343 probability\n",
      "Team 1401 wins: 1154 vs 1401 with 0.9343 probability\n",
      "Team 1397 wins: 1397 vs 1419 with 0.9343 probability\n",
      "Team 1116 wins: 1116 vs 1154 with 0.9343 probability\n",
      "Team 1181 wins: 1181 vs 1212 with 0.9343 probability\n",
      "Team 1281 wins: 1154 vs 1281 with 0.9343 probability\n",
      "Team 1397 wins: 1397 vs 1480 with 0.9343 probability\n",
      "Team 1208 wins: 1208 vs 1271 with 0.9343 probability\n",
      "Team 1385 wins: 1290 vs 1385 with 0.9343 probability\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load predictions\n",
    "predictions = pd.read_csv('submission.csv')\n",
    "\n",
    "# Print a sample to understand the format\n",
    "print(\"Sample of the submission file:\")\n",
    "print(predictions.head())\n",
    "\n",
    "# Extract parts more safely\n",
    "print(\"\\nExtracting ID parts...\")\n",
    "# First, let's look at what we're dealing with\n",
    "print(\"Sample IDs:\", predictions['ID'].head().tolist())\n",
    "\n",
    "# Split the ID string and handle potential decimal points\n",
    "id_parts = predictions['ID'].str.split('_', expand=True)\n",
    "predictions['Season'] = id_parts[0].str.replace('.0', '').astype(str)\n",
    "predictions['Team1ID'] = pd.to_numeric(id_parts[1].str.replace('.0', ''))\n",
    "predictions['Team2ID'] = pd.to_numeric(id_parts[2].str.replace('.0', ''))\n",
    "\n",
    "print(\"\\nAfter extraction:\")\n",
    "print(predictions[['ID', 'Season', 'Team1ID', 'Team2ID']].head())\n",
    "\n",
    "# Show raw predictions\n",
    "print(\"\\nTop 10 most confident predictions:\")\n",
    "predictions['Confidence'] = predictions['Pred'].apply(lambda x: max(x, 1-x))\n",
    "sorted_preds = predictions[['ID', 'Pred', 'Team1ID', 'Team2ID', 'Confidence']].sort_values('Confidence', ascending=False)\n",
    "print(sorted_preds.head(10))\n",
    "\n",
    "# If you want to try loading team names again\n",
    "try:\n",
    "    print(\"\\nAttempting to load team names...\")\n",
    "    # Try different potential paths\n",
    "    paths = [\n",
    "        './data/MTeams.csv',\n",
    "        'MTeams.csv',\n",
    "        '../data/MTeams.csv',\n",
    "        'data/MTeams.csv'\n",
    "    ]\n",
    "    \n",
    "    m_teams_loaded = False\n",
    "    w_teams_loaded = False\n",
    "    \n",
    "    for path in paths:\n",
    "        try:\n",
    "            base_path = path.replace('MTeams.csv', '')\n",
    "            m_teams = pd.read_csv(f\"{base_path}MTeams.csv\")\n",
    "            w_teams = pd.read_csv(f\"{base_path}WTeams.csv\")\n",
    "            m_teams_loaded = True\n",
    "            w_teams_loaded = True\n",
    "            print(f\"Found teams files in {base_path}\")\n",
    "            break\n",
    "        except FileNotFoundError:\n",
    "            continue\n",
    "    \n",
    "    if m_teams_loaded and w_teams_loaded:\n",
    "        # Continue with team name matching\n",
    "        teams = pd.concat([m_teams, w_teams])\n",
    "        print(f\"Loaded {len(teams)} teams\")\n",
    "        \n",
    "        # Add team names\n",
    "        predictions = predictions.merge(teams[['TeamID', 'TeamName']], \n",
    "                                     left_on='Team1ID', right_on='TeamID', \n",
    "                                     how='left').drop('TeamID', axis=1)\n",
    "        predictions = predictions.merge(teams[['TeamID', 'TeamName']], \n",
    "                                     left_on='Team2ID', right_on='TeamID', \n",
    "                                     how='left').drop('TeamID', axis=1)\n",
    "        predictions.rename(columns={'TeamName_x': 'Team1Name', 'TeamName_y': 'Team2Name'}, inplace=True)\n",
    "        \n",
    "        # Add predicted winner\n",
    "        predictions['PredictedWinner'] = predictions.apply(\n",
    "            lambda row: row['Team1Name'] if row['Pred'] > 0.5 else row['Team2Name'], axis=1\n",
    "        )\n",
    "        predictions['WinProbability'] = predictions.apply(\n",
    "            lambda row: row['Pred'] if row['Pred'] > 0.5 else 1 - row['Pred'], axis=1\n",
    "        )\n",
    "        \n",
    "        print(\"\\nSample with team names:\")\n",
    "        print(predictions[['Team1Name', 'Team2Name', 'PredictedWinner', 'WinProbability']].head(10))\n",
    "    else:\n",
    "        print(\"Could not find team files. Displaying IDs only.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading team names: {e}\")\n",
    "    print(\"Continuing with team IDs only\")\n",
    "\n",
    "# Print most predictable winners\n",
    "print(\"\\nMost confident predictions:\")\n",
    "print(\"Team1ID beats Team2ID with probability Pred\")\n",
    "for _, row in sorted_preds.head(20).iterrows():\n",
    "    team1, team2 = int(row['Team1ID']), int(row['Team2ID'])\n",
    "    prob = row['Pred']\n",
    "    winner = f\"Team {team1}\" if prob > 0.5 else f\"Team {team2}\"\n",
    "    win_prob = prob if prob > 0.5 else 1-prob\n",
    "    print(f\"{winner} wins: {team1} vs {team2} with {win_prob:.4f} probability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top teams (most likely tournament winners):\n",
      "   TeamID  HighConfWins     TeamName\n",
      "0    1120           351       Auburn\n",
      "1    1196           337      Florida\n",
      "2    1104           334      Alabama\n",
      "3    1181           330         Duke\n",
      "4    1222           325      Houston\n",
      "5    1397           322    Tennessee\n",
      "6    1246           316     Kentucky\n",
      "7    1385           314    St John's\n",
      "8    1277           311  Michigan St\n",
      "9    1279           308  Mississippi\n"
     ]
    }
   ],
   "source": [
    "# Count which teams win most often with high confidence\n",
    "team_win_counts = {}\n",
    "high_conf_threshold = 0.85  # Only count high confidence wins\n",
    "\n",
    "for _, row in predictions.iterrows():\n",
    "    team1 = row['Team1ID']\n",
    "    team2 = row['Team2ID']\n",
    "    pred = row['Pred']\n",
    "    \n",
    "    if pred > 0.5 and pred > high_conf_threshold:\n",
    "        winner = team1\n",
    "    elif pred < 0.5 and (1-pred) > high_conf_threshold:\n",
    "        winner = team2\n",
    "    else:\n",
    "        continue  # Skip low confidence matchups\n",
    "    \n",
    "    if winner in team_win_counts:\n",
    "        team_win_counts[winner] += 1\n",
    "    else:\n",
    "        team_win_counts[winner] = 1\n",
    "\n",
    "# Convert to DataFrame and get top teams\n",
    "win_counts_df = pd.DataFrame({\n",
    "    'TeamID': list(team_win_counts.keys()),\n",
    "    'HighConfWins': list(team_win_counts.values())\n",
    "}).sort_values('HighConfWins', ascending=False)\n",
    "\n",
    "# Get team names\n",
    "top_teams = win_counts_df.merge(teams[['TeamID', 'TeamName']], on='TeamID', how='left')\n",
    "print(\"\\nTop teams (most likely tournament winners):\")\n",
    "print(top_teams.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
